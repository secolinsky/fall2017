* Tasks
** TODO Study for exam
<2017-09-13 Wed>
** TODO First HW due
Includes 20 Assignments DEADLINE: <2017-09-12 Tue> at midnight
** TODO Data set HW
DEADLINE: <2017-09-11 Mon>
- Pick 3 data sets
- use the data to calculate descriptive measures and
  graphs using "three methods" as template
** TODO Weather Data Set HW
DEADLINE: <2017-09-11 Mon>
[[https://www.wunderground.com/history/airport/RJTT/2016/6/1/MonthlyCalendar.html?req_city%3DAraijuku&req_state%3D&req_statename%3DJapan&reqdb.zip%3D&reqdb.magic%3D&reqdb.wmo%3D&MR%3D1][weather data]]
** TODO Toss a coin 100 times.  Calculate the probability of exactly 50 heads.
#+BEGIN_SRC sage
N(binomial(100,5)/2^100,5)
#+END_SRC
* Lecture Notes
** Observational study
- someone is observing data that already exist.
- Observational studies can reveal only association, 
** Experimental study
- data do not exist until someone does an experiment that produces the data
- designed experiments can help establish causation, or cause and effect. In a 
  designed experiment, researchers impose treatments and controls, and then 
  observe characteristics and take measurements. 

** Organizing the Data
- Distributed within bins
** Variables
- Qualitative
- Quantitative
- Discrete
- Continuous
** Distributing the data
*** Continuous Distributions
- Normal
- Chi-Square
- F

*** Frequency Distributions - Histograms
- Relative frequency
*** Bar Chart
- Dividing scale to classes, then bin the data according to classes
- heigths being relative frequency

** Grouping Method
** Scatter Plot
** Stem-and-Leaf
** Mean
the sum of the observations divided by the number of observations
** Median
Arrange in increasing order
- n is odd implies median at the middle
- n is even, then take average of the middle observations
** Mode
Most frequent value
** Three Standard Deviation Rule

* Homework Notes
[[http://www.mystatlab.com/][Pearson site]]
** [[https://onlinecourses.science.psu.edu/stat506/node/27][Stratified Random Sampling]]
Population partitioned called strata and a sample is selected by some design within each stratum.
Reasons for using stratified random sampling than simple random sampling include the following
1. Stratification may produce a smaller error of estimation than would be produced by a 
simple random sample of the same size. This result is particularly true if measurements 
within strata are very homogeneous.
2. The cost per observation in the survey may be reduced by stratification of the population elements 
into convenient groupings.
3. Estimates of population parameters may be desired for subgroups of the population. These 
subgroups should then be identified. 
** [[http://stattrek.com/experiments/experimental-design.aspx?Tutorial%3DAP][Experimental Design]]
A plan for assigning experimental units to treatment conditions.  Three purposes are to 
1. allow to make causal inferences about the relationship between independent variables and a dependent variable
2. to rule out alternative explanations due to the confounding effects of extraneous variables
3. reduce variability within treatment conditions making it easier to detect differences in treatment outcomes
*** Examples
- Randomized design
  - participants randomly assigned treatments
  - relies on on radomness to control for the effects of extraneous variables.
    The assumption is that on average, extraneous factors will affect treatment conditions equally.
- Randomized block design
  - Participants divided into subgroups called blocks, 
    such that variability within blocks is less than the
    variability  between blocks.  Then participants within each
    block are randomly assigned to treatment conditions.
  - Blocks perform a similar function in experimental design as strata perform in sampling.
    Both divide observations into subgroups.  However, they are not the same.  Blocking
    is associated with experimental design, and stratification is associated with survey sampling.
- Matched pairs design
  - Special case of the randomized block design.
    Used when the experiment has only two treatment conditions and 
    participants can be grouped into pairs, based on some blocking
    variable.  Then, within each pair, participants are randomly assigned
    to different treatments.
** [[https://faculty.elgin.edu/dkernler/statistics/ch01/1-6.html][Designed Experiments]]
A controlled study in which one or more treatments are applied to experimental units (subjects).
- one-factor experiment
- levels of a single factor represent the number of treatments
- experimental unit
  - person or object which the treatment is applied
- treatment
  - condition applied to the experimental unit
- response variable
  - the variable of interest
- factors
  - variables which affect the response variable
*** Steps in Designing an Experiment
1. Identify the problem or claim to be studied
   - must identify the response variable and the population to be studied
2. Determine the factors affecting the response variable
3. Determine the number of experimental units
4. Determine the levels of each factor
   - Control to fix the level of factors that we're not interested in
   - Manipulate the levels of the variable that is thought to affect the response variable
   - Randomize so that factors can be equally spread among all groups
    
** [[https://blog.heapanalytics.com/how-to-lie-with-data-visualization/][misleading graphs]]
** Inter Quartile Range
Gives the middle 50% span of data 
* R Code
** Notes
- Good [[https://www.tutorialspoint.com/r/r_data_types.htm][R tutorial]]
- A data frame in R is used for storing data tables
  - Unlike a matrix, each column of data frame can contain 
   different modes of data
- R commands  
  1. Create dotplots with the dotchart(x, labels=) function
- ESS commands
  1. M-p Select the previous command in the input history
     - M-n Select the next command in the input history
  2. <s + TAB wil give code block
- [[https://www.datacamp.com/community/tutorials/r-tutorial-read-excel-into-r/#gs.Y5UcN4A][Read data]] from a text file into R with read.table("<FileName>.txt",header=TRUE)
- create a dot plot with dotchart(x,labels) function
- create a stem-and-leaf plot with stem(x)
- type'_' to make assignment with '<-' and type it again for normal output
** Make current prompt on top
from [[https://stackoverflow.com/questions/14301722/how-to-make-the-current-prompt-of-r-at-the-top-of-buffer-in-ess-just-like-contro][stackoverflow]]
How to make the current prompt of R at the top of buffer in ESS 
just like Control + L in R console?

Answer:

For me Esc-0 Ctr-l seems to work.

`Ctrl-h k' output is:

C-l runs the command recenter-top-bottom,
which is an interactive compiled Lisp function in window.el'.

According to this page from the Emacs manual:

Scroll the selected window so the current line is the 
center-most text line; on subsequent consecutive invocations,
make the current line the top line, the bottom line, and so on in
cyclic order. Possibly redisplay the screen too (recenter-top-bottom). 
** How to do a Frequency Distribution of Quantitative Data
Taken from [[http://www.r-tutor.com/elementary-statistics/quantitative-data/frequency-distribution-quantitative-data][Frequency Distribution of Quantitative Data]] that uses the dataset faithful:

head(faithful)
  eruptions waiting
1     3.600      79
2     1.800      54
3     3.333      74
4     2.283      62
5     4.533      85
6     2.883      55

- First get range of data using range()
  #+BEGIN_SRC R 
  duration = faithful$eruptions 
  range(duration)
  #+END_SRC

- Break range into non-overlapping sub-intervals by defining a 
  sequence of equal distance break points using seq().
  #+BEGIN_SRC R 
  breaks = seq(1.5,5.5,byte=0.5)
  #+END_SRC

- Classify the eruption durations according to the half-unit-length sub-intervals with cut(). 
  As the intervals are to be closed on the left, and open on the right, we set the right argument as FALSE.
  #+BEGIN_SRC R 
  duration.cut = cut(duration, breaks, right=FALSE)
  #+END_SRC

- Compute the frequency of eruptions in each sub-interval with the table()
  #+BEGIN_SRC R 
  duration.freq = table(duration.cut)
  #+END_SRC

- frequency distribution is below
  #+BEGIN_SRC R 
  duration.freq
  #+END_SRC

- To print result in column format use cbind()
  #+BEGIN_SRC R 
  cbind(duration.freq)
  #+END_SRC

** How to do a histogram with R
#+BEGIN_SRC R 
hist(duration,    # apply the hist function 
   right=FALSE)    # intervals closed on the left 
#+END_SRC
** [[http://www.theanalysisfactor.com/r-tutorial-count/][Counting Elements in a Data Set]]
Combining the lenght() and which() commands gives a handy method of countin
elements that meet particular criteria.
#+BEGIN_SRC R
d=c('a','c','a','e','b','e','d','c','e','b','c','a','d','b','b','d','e',
'b','c','c','a','c','e','e','c')
count <- function(letter) { length(which(d==letter)) }
count('a')
#+END_SRC

#+RESULTS:
: 4
To get a table of frequencies from dataset, 
#+BEGIN_SRC R
d=c('a','c','a','e','b','e','d','c','e','b','c','a','d','b','b','d','e',
'b','c','c','a','c','e','e','c')
table(d)
#+END_SRC

#+RESULTS:
| a | 4 |
| b | 5 |
| c | 7 |
| d | 3 |
| e | 6 |

To get a table of relative frequencies from dataset, 
#+BEGIN_SRC R
d=c('a','c','a','e','b','e','d','c','e','b','c','a','d','b','b','d','e',
'b','c','c','a','c','e','e','c')
table(d)/length(d)
#+END_SRC

#+RESULTS:
| a | 0.16 |
| b |  0.2 |
| c | 0.28 |
| d | 0.12 |
| e | 0.24 |

** Factors R-Object
Stores vector along with the distinct values of the elements
#+BEGIN_SRC R
apple_colors <- c('green','green','yellow','red','red','red','green')
factor_apple <- factor(apple_colors)
print(factor_apple)
#+END_SRC

#+RESULTS:
| green  |
| green  |
| yellow |
| red    |
| red    |
| red    |
| green  |

#+BEGIN_SRC R
apple_colors <- c('green','green','yellow','red','red','red','green')
factor_apple <- factor(apple_colors)
print(nlevels(factor_apple))
#+END_SRC

#+RESULTS:
: 3
** limit grouping
Turning [[https://www.r-bloggers.com/from-continuous-to-categorical/][From continuous to categorical]]
#+BEGIN_SRC R
x <- c(2,6,14,21,29,11,11,20,24,6,15,17,22,27,9,6,4,9,6,6)
mydata<-cut(x,seq(0,30,5),right=FALSE)
table(mydata)
#+END_SRC

#+RESULTS:
| [0,5)   | 2 |
| [5,10)  | 7 |
| [10,15) | 3 |
| [15,20) | 2 |
| [20,25) | 4 |
| [25,30) | 2 |

** Mode of a data set
#+BEGIN_SRC R
# Create the function.
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
#+END_SRC
** Column sd and mean
colMeans(d) and apply(d,2,sd) where d is your collection of data sets
** Quartiles
- Output of quantile function is a five-number summary
Q_0,Q_1,Q_2,Q_3,Q_4
#+BEGIN_SRC R
quantile(c(3,5,6,8,9,3,5,6,8,9))
#+END_SRC

#+RESULTS:
| 3 |
| 5 |
| 6 |
| 8 |
| 9 |
Here is a good reference for creating [[https://www.r-bloggers.com/box-plot-with-r-tutorial/][box-plots]]
- Interquartile range found with IQR function

* Sed notes
- join all lines of a file using sed
  sed ':a; $s/\n/ /g; N; ba'
- lowercase the first letter of every line
  sed 's/.*/\L&/'
- put all words in quote
  sed -i 's/[^ ][^ ]*/"&"/g' filename
- add comma between each word
  sed -i 's/\>/,/g;s/,$//' data.txt
* Wunderground API key
[[https://www.wunderground.com/weather/api/d/c827faffa5416342/edit.html?api_action%3Dchangesubscription&api_history%3Dundefined&api_usage%3D0&api_package%3Da][site]] gave key c827faffa5416342
** Example Code
   - First example http://api.wunderground.com/api/c827faffa5416342/conditions/q/CA/San_Francisco.json
